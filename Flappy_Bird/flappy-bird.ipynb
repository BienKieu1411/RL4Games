{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install stable-baselines3\n!pip install gymnasium\n!pip install flappy-bird-gymnasium\n!pip install imageio\n!pip install pygame","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T21:39:40.363137Z","iopub.execute_input":"2025-08-29T21:39:40.363320Z","iopub.status.idle":"2025-08-29T21:41:38.257951Z","shell.execute_reply.started":"2025-08-29T21:39:40.363302Z","shell.execute_reply":"2025-08-29T21:41:38.255924Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.1.0)\nRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (0.29.0)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.26.4)\nRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.7.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.14.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->stable-baselines3)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->stable-baselines3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->stable-baselines3) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->stable-baselines3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->stable-baselines3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->stable-baselines3) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (0.29.0)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->gymnasium) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.0->gymnasium) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.0->gymnasium) (2024.2.0)\nCollecting flappy-bird-gymnasium\n  Downloading flappy_bird_gymnasium-0.4.0-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (from flappy-bird-gymnasium) (0.29.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from flappy-bird-gymnasium) (1.26.4)\nRequirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from flappy-bird-gymnasium) (2.6.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from flappy-bird-gymnasium) (3.7.2)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->flappy-bird-gymnasium) (3.1.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->flappy-bird-gymnasium) (4.14.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium->flappy-bird-gymnasium) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->flappy-bird-gymnasium) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->flappy-bird-gymnasium) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->flappy-bird-gymnasium) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->flappy-bird-gymnasium) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->flappy-bird-gymnasium) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->flappy-bird-gymnasium) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->flappy-bird-gymnasium) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->flappy-bird-gymnasium) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->flappy-bird-gymnasium) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->flappy-bird-gymnasium) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->flappy-bird-gymnasium) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->flappy-bird-gymnasium) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->flappy-bird-gymnasium) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->flappy-bird-gymnasium) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->flappy-bird-gymnasium) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->flappy-bird-gymnasium) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->flappy-bird-gymnasium) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->flappy-bird-gymnasium) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->flappy-bird-gymnasium) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->flappy-bird-gymnasium) (2024.2.0)\nDownloading flappy_bird_gymnasium-0.4.0-py3-none-any.whl (37.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: flappy-bird-gymnasium\nSuccessfully installed flappy-bird-gymnasium-0.4.0\nRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio) (1.26.4)\nRequirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->imageio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->imageio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->imageio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->imageio) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->imageio) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->imageio) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->imageio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->imageio) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->imageio) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->imageio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->imageio) (2024.2.0)\nRequirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (2.6.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport argparse\nfrom pathlib import Path\nimport warnings\nimport gymnasium as gym\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\nfrom stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback, StopTrainingOnRewardThreshold\nfrom gym.wrappers import RecordVideo\n\nos.environ[\"XDG_RUNTIME_DIR\"] = \"/tmp\"\nwarnings.filterwarnings(\"ignore\")\n\ndef ensure_dir(path):\n    Path(path).mkdir(parents=True, exist_ok=True)\n\ndef default_output_dir(save_dir):\n    out_dir = Path(save_dir) / \"flappy_ppo\"\n    ensure_dir(out_dir)\n    return out_dir\n\ndef make_flappy_env(render_mode=None, seed=0):\n    def _init():\n        env = gym.make(\"FlappyBird-v0\", render_mode=render_mode)\n        env.reset(seed=seed)\n        return env\n    return _init\n\ndef make_vec_envs(n_envs=1, seed=0):\n    envs = DummyVecEnv([make_flappy_env(seed=i+seed) for i in range(n_envs)])\n    envs = VecMonitor(envs)\n    return envs\n\ndef parse_args():\n    p = argparse.ArgumentParser()\n    p.add_argument(\"--timesteps\", type=int, default=1_000_000)\n    p.add_argument(\"--save_dir\", type=str, default=\"outputs\")\n    p.add_argument(\"--reward_threshold\", type=float, default=100.0)\n    p.add_argument(\"--render_video\", action=\"store_true\")\n    return p.parse_args(args=[\"--render_video\"])\n\ndef main():\n    args = parse_args()\n    out_dir = default_output_dir(args.save_dir)\n    log_dir = out_dir / \"logs\"\n    ensure_dir(log_dir)\n\n    train_env = make_vec_envs(1)\n    eval_env = make_vec_envs(1, seed=42)\n\n    model = PPO(\n        \"MlpPolicy\",\n        train_env,\n        verbose=1,\n        tensorboard_log=str(log_dir),\n        device=\"cuda\",\n        n_steps=10000,\n        batch_size=512\n    )\n\n    checkpoint_callback = CheckpointCallback(\n        save_freq=100_000,\n        save_path=str(out_dir / \"checkpoints\"),\n        name_prefix=\"ppo_flappy\"\n    )\n\n    stop_callback = StopTrainingOnRewardThreshold(\n        reward_threshold=args.reward_threshold,\n        verbose=1\n    )\n\n    eval_callback = EvalCallback(\n        eval_env,\n        callback_on_new_best=checkpoint_callback,\n        best_model_save_path=str(out_dir / \"best_model\"),\n        log_path=str(out_dir / \"eval_logs\"),\n        eval_freq=50_000,\n        n_eval_episodes=5,\n        deterministic=True,\n        render=False,\n        callback_after_eval=stop_callback\n    )\n\n    model.learn(total_timesteps=args.timesteps, callback=[eval_callback])\n    model.save(str(out_dir / \"final_model.zip\"))\n\n    if args.render_video:\n        video_path = out_dir / \"flappy_video\"\n        ensure_dir(video_path)\n\n        env = gym.make(\"FlappyBird-v0\", render_mode=\"rgb_array\")\n        env = RecordVideo(env, str(video_path), episode_trigger=lambda x: True)\n\n        best_model_path = out_dir / \"best_model\" / \"best_model.zip\"\n        model = PPO.load(str(best_model_path))\n\n        obs, _ = env.reset(seed=0)\n        done = False\n        while not done:\n            action, _ = model.predict(obs, deterministic=True)\n            action = int(action)\n\n            step_result = env.step(action)\n            if len(step_result) == 5:\n                obs, reward, terminated, truncated, info = step_result\n                done = terminated or truncated\n            else:\n                obs, reward, done, info = step_result\n\n        env.close()\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T22:33:19.284423Z","iopub.execute_input":"2025-08-29T22:33:19.285455Z","iopub.status.idle":"2025-08-29T22:48:29.333488Z","shell.execute_reply.started":"2025-08-29T22:33:19.285426Z","shell.execute_reply":"2025-08-29T22:48:29.332284Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Using cpu device\nLogging to outputs/flappy_ppo/logs/PPO_4\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 50       |\n|    ep_rew_mean     | -7.47    |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 1        |\n|    time_elapsed    | 22       |\n|    total_timesteps | 10000    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 50          |\n|    ep_rew_mean          | -6.276001   |\n| time/                   |             |\n|    fps                  | 422         |\n|    iterations           | 2           |\n|    time_elapsed         | 47          |\n|    total_timesteps      | 20000       |\n| train/                  |             |\n|    approx_kl            | 0.015574029 |\n|    clip_fraction        | 0.0905      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.679      |\n|    explained_variance   | 0.032       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0722      |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.00634    |\n|    value_loss           | 1.23        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 50          |\n|    ep_rew_mean          | -5.172001   |\n| time/                   |             |\n|    fps                  | 419         |\n|    iterations           | 3           |\n|    time_elapsed         | 71          |\n|    total_timesteps      | 30000       |\n| train/                  |             |\n|    approx_kl            | 0.012357075 |\n|    clip_fraction        | 0.076       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.647      |\n|    explained_variance   | 0.821       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.128       |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00926    |\n|    value_loss           | 0.51        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 50          |\n|    ep_rew_mean          | -3.0900016  |\n| time/                   |             |\n|    fps                  | 419         |\n|    iterations           | 4           |\n|    time_elapsed         | 95          |\n|    total_timesteps      | 40000       |\n| train/                  |             |\n|    approx_kl            | 0.011138743 |\n|    clip_fraction        | 0.163       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.591      |\n|    explained_variance   | 0.805       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.227       |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0143     |\n|    value_loss           | 0.538       |\n-----------------------------------------\nEval num_timesteps=50000, episode_reward=0.80 +/- 0.00\nEpisode length: 31.00 +/- 0.00\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 31          |\n|    mean_reward          | 0.8         |\n| time/                   |             |\n|    total_timesteps      | 50000       |\n| train/                  |             |\n|    approx_kl            | 0.019868212 |\n|    clip_fraction        | 0.155       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.52       |\n|    explained_variance   | 0.696       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.307       |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0159     |\n|    value_loss           | 0.686       |\n-----------------------------------------\nNew best mean reward!\n-----------------------------------\n| rollout/           |            |\n|    ep_len_mean     | 50         |\n|    ep_rew_mean     | -1.5890014 |\n| time/              |            |\n|    fps             | 417        |\n|    iterations      | 5          |\n|    time_elapsed    | 119        |\n|    total_timesteps | 50000      |\n-----------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 50.3        |\n|    ep_rew_mean          | -0.49600154 |\n| time/                   |             |\n|    fps                  | 416         |\n|    iterations           | 6           |\n|    time_elapsed         | 143         |\n|    total_timesteps      | 60000       |\n| train/                  |             |\n|    approx_kl            | 0.018608548 |\n|    clip_fraction        | 0.131       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.425      |\n|    explained_variance   | 0.456       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.277       |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -0.0106     |\n|    value_loss           | 0.555       |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 50.6         |\n|    ep_rew_mean          | -0.14900164  |\n| time/                   |              |\n|    fps                  | 416          |\n|    iterations           | 7            |\n|    time_elapsed         | 167          |\n|    total_timesteps      | 70000        |\n| train/                  |              |\n|    approx_kl            | 0.0074359104 |\n|    clip_fraction        | 0.0573       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.329       |\n|    explained_variance   | 0.551        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.141        |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.00365     |\n|    value_loss           | 0.383        |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 51.1         |\n|    ep_rew_mean          | -0.095001675 |\n| time/                   |              |\n|    fps                  | 416          |\n|    iterations           | 8            |\n|    time_elapsed         | 192          |\n|    total_timesteps      | 80000        |\n| train/                  |              |\n|    approx_kl            | 0.0037213932 |\n|    clip_fraction        | 0.0384       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.331       |\n|    explained_variance   | 0.759        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.117        |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.00428     |\n|    value_loss           | 0.339        |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 52.5         |\n|    ep_rew_mean          | 0.6709981    |\n| time/                   |              |\n|    fps                  | 414          |\n|    iterations           | 9            |\n|    time_elapsed         | 217          |\n|    total_timesteps      | 90000        |\n| train/                  |              |\n|    approx_kl            | 0.0033943248 |\n|    clip_fraction        | 0.0406       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.315       |\n|    explained_variance   | 0.831        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.148        |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.00652     |\n|    value_loss           | 0.33         |\n------------------------------------------\nEval num_timesteps=100000, episode_reward=0.80 +/- 0.00\nEpisode length: 31.00 +/- 0.00\n------------------------------------------\n| eval/                   |              |\n|    mean_ep_length       | 31           |\n|    mean_reward          | 0.8          |\n| time/                   |              |\n|    total_timesteps      | 100000       |\n| train/                  |              |\n|    approx_kl            | 0.0035073813 |\n|    clip_fraction        | 0.0409       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.304       |\n|    explained_variance   | 0.802        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.161        |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.00611     |\n|    value_loss           | 0.362        |\n------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 52.7     |\n|    ep_rew_mean     | 0.966998 |\n| time/              |          |\n|    fps             | 411      |\n|    iterations      | 10       |\n|    time_elapsed    | 242      |\n|    total_timesteps | 100000   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 54.3       |\n|    ep_rew_mean          | 1.9449975  |\n| time/                   |            |\n|    fps                  | 411        |\n|    iterations           | 11         |\n|    time_elapsed         | 267        |\n|    total_timesteps      | 110000     |\n| train/                  |            |\n|    approx_kl            | 0.00826907 |\n|    clip_fraction        | 0.0839     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.295     |\n|    explained_variance   | 0.785      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 0.207      |\n|    n_updates            | 100        |\n|    policy_gradient_loss | -0.0116    |\n|    value_loss           | 0.407      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 59          |\n|    ep_rew_mean          | 2.4519973   |\n| time/                   |             |\n|    fps                  | 409         |\n|    iterations           | 12          |\n|    time_elapsed         | 292         |\n|    total_timesteps      | 120000      |\n| train/                  |             |\n|    approx_kl            | 0.003915688 |\n|    clip_fraction        | 0.0465      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.283      |\n|    explained_variance   | 0.789       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.133       |\n|    n_updates            | 110         |\n|    policy_gradient_loss | -0.00724    |\n|    value_loss           | 0.332       |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 65.7         |\n|    ep_rew_mean          | 3.1819973    |\n| time/                   |              |\n|    fps                  | 409          |\n|    iterations           | 13           |\n|    time_elapsed         | 317          |\n|    total_timesteps      | 130000       |\n| train/                  |              |\n|    approx_kl            | 0.0053049996 |\n|    clip_fraction        | 0.0479       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.233       |\n|    explained_variance   | 0.786        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.146        |\n|    n_updates            | 120          |\n|    policy_gradient_loss | -0.00791     |\n|    value_loss           | 0.329        |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 76          |\n|    ep_rew_mean          | 4.025998    |\n| time/                   |             |\n|    fps                  | 409         |\n|    iterations           | 14          |\n|    time_elapsed         | 341         |\n|    total_timesteps      | 140000      |\n| train/                  |             |\n|    approx_kl            | 0.008303092 |\n|    clip_fraction        | 0.0406      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.219      |\n|    explained_variance   | 0.775       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.189       |\n|    n_updates            | 130         |\n|    policy_gradient_loss | -0.00697    |\n|    value_loss           | 0.36        |\n-----------------------------------------\nEval num_timesteps=150000, episode_reward=16.26 +/- 18.12\nEpisode length: 204.20 +/- 193.99\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 204         |\n|    mean_reward          | 16.3        |\n| time/                   |             |\n|    total_timesteps      | 150000      |\n| train/                  |             |\n|    approx_kl            | 0.004532953 |\n|    clip_fraction        | 0.0477      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.226      |\n|    explained_variance   | 0.725       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.22        |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.00732    |\n|    value_loss           | 0.471       |\n-----------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 77.8     |\n|    ep_rew_mean     | 4.264998 |\n| time/              |          |\n|    fps             | 407      |\n|    iterations      | 15       |\n|    time_elapsed    | 368      |\n|    total_timesteps | 150000   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 111         |\n|    ep_rew_mean          | 6.633004    |\n| time/                   |             |\n|    fps                  | 406         |\n|    iterations           | 16          |\n|    time_elapsed         | 393         |\n|    total_timesteps      | 160000      |\n| train/                  |             |\n|    approx_kl            | 0.004246485 |\n|    clip_fraction        | 0.0413      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.175      |\n|    explained_variance   | 0.717       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.259       |\n|    n_updates            | 150         |\n|    policy_gradient_loss | -0.00682    |\n|    value_loss           | 0.524       |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 132          |\n|    ep_rew_mean          | 8.192011     |\n| time/                   |              |\n|    fps                  | 406          |\n|    iterations           | 17           |\n|    time_elapsed         | 417          |\n|    total_timesteps      | 170000       |\n| train/                  |              |\n|    approx_kl            | 0.0036758562 |\n|    clip_fraction        | 0.0298       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.143       |\n|    explained_variance   | 0.503        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.426        |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.00463     |\n|    value_loss           | 0.766        |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 154          |\n|    ep_rew_mean          | 9.8730135    |\n| time/                   |              |\n|    fps                  | 407          |\n|    iterations           | 18           |\n|    time_elapsed         | 441          |\n|    total_timesteps      | 180000       |\n| train/                  |              |\n|    approx_kl            | 0.0029585352 |\n|    clip_fraction        | 0.0277       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.117       |\n|    explained_variance   | 0.494        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.332        |\n|    n_updates            | 170          |\n|    policy_gradient_loss | -0.00336     |\n|    value_loss           | 0.799        |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 199          |\n|    ep_rew_mean          | 13.774998    |\n| time/                   |              |\n|    fps                  | 407          |\n|    iterations           | 19           |\n|    time_elapsed         | 465          |\n|    total_timesteps      | 190000       |\n| train/                  |              |\n|    approx_kl            | 0.0014597684 |\n|    clip_fraction        | 0.0241       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0976      |\n|    explained_variance   | 0.407        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.433        |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.00215     |\n|    value_loss           | 1            |\n------------------------------------------\nEval num_timesteps=200000, episode_reward=48.82 +/- 24.33\nEpisode length: 537.00 +/- 261.98\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 537         |\n|    mean_reward          | 48.8        |\n| time/                   |             |\n|    total_timesteps      | 200000      |\n| train/                  |             |\n|    approx_kl            | 0.002380191 |\n|    clip_fraction        | 0.0201      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.0876     |\n|    explained_variance   | 0.321       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.427       |\n|    n_updates            | 190         |\n|    policy_gradient_loss | -0.00253    |\n|    value_loss           | 0.939       |\n-----------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 244      |\n|    ep_rew_mean     | 18.09297 |\n| time/              |          |\n|    fps             | 403      |\n|    iterations      | 20       |\n|    time_elapsed    | 495      |\n|    total_timesteps | 200000   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 286         |\n|    ep_rew_mean          | 21.808952   |\n| time/                   |             |\n|    fps                  | 404         |\n|    iterations           | 21          |\n|    time_elapsed         | 519         |\n|    total_timesteps      | 210000      |\n| train/                  |             |\n|    approx_kl            | 0.002534771 |\n|    clip_fraction        | 0.0177      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.0645     |\n|    explained_variance   | 0.282       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.45        |\n|    n_updates            | 200         |\n|    policy_gradient_loss | -0.00175    |\n|    value_loss           | 0.894       |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 309          |\n|    ep_rew_mean          | 23.802935    |\n| time/                   |              |\n|    fps                  | 404          |\n|    iterations           | 22           |\n|    time_elapsed         | 543          |\n|    total_timesteps      | 220000       |\n| train/                  |              |\n|    approx_kl            | 0.0026360927 |\n|    clip_fraction        | 0.018        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0672      |\n|    explained_variance   | 0.331        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.48         |\n|    n_updates            | 210          |\n|    policy_gradient_loss | -0.00137     |\n|    value_loss           | 0.888        |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 313          |\n|    ep_rew_mean          | 24.490932    |\n| time/                   |              |\n|    fps                  | 404          |\n|    iterations           | 23           |\n|    time_elapsed         | 568          |\n|    total_timesteps      | 230000       |\n| train/                  |              |\n|    approx_kl            | 0.0017670132 |\n|    clip_fraction        | 0.0143       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0553      |\n|    explained_variance   | 0.355        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.513        |\n|    n_updates            | 220          |\n|    policy_gradient_loss | -0.00217     |\n|    value_loss           | 1.07         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 333          |\n|    ep_rew_mean          | 26.344917    |\n| time/                   |              |\n|    fps                  | 404          |\n|    iterations           | 24           |\n|    time_elapsed         | 593          |\n|    total_timesteps      | 240000       |\n| train/                  |              |\n|    approx_kl            | 0.0011697053 |\n|    clip_fraction        | 0.012        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0576      |\n|    explained_variance   | 0.381        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.416        |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.00132     |\n|    value_loss           | 1.03         |\n------------------------------------------\nEval num_timesteps=250000, episode_reward=53.20 +/- 36.23\nEpisode length: 592.80 +/- 378.95\n------------------------------------------\n| eval/                   |              |\n|    mean_ep_length       | 593          |\n|    mean_reward          | 53.2         |\n| time/                   |              |\n|    total_timesteps      | 250000       |\n| train/                  |              |\n|    approx_kl            | 0.0011315796 |\n|    clip_fraction        | 0.0146       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0553      |\n|    explained_variance   | 0.433        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.543        |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.00099     |\n|    value_loss           | 1            |\n------------------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/           |           |\n|    ep_len_mean     | 336       |\n|    ep_rew_mean     | 26.556913 |\n| time/              |           |\n|    fps             | 399       |\n|    iterations      | 25        |\n|    time_elapsed    | 625       |\n|    total_timesteps | 250000    |\n----------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 391          |\n|    ep_rew_mean          | 31.676868    |\n| time/                   |              |\n|    fps                  | 400          |\n|    iterations           | 26           |\n|    time_elapsed         | 649          |\n|    total_timesteps      | 260000       |\n| train/                  |              |\n|    approx_kl            | 0.0023459566 |\n|    clip_fraction        | 0.0189       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0524      |\n|    explained_variance   | 0.434        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.741        |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -0.00174     |\n|    value_loss           | 1.21         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 423          |\n|    ep_rew_mean          | 34.53187     |\n| time/                   |              |\n|    fps                  | 400          |\n|    iterations           | 27           |\n|    time_elapsed         | 674          |\n|    total_timesteps      | 270000       |\n| train/                  |              |\n|    approx_kl            | 0.0016000301 |\n|    clip_fraction        | 0.0153       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0455      |\n|    explained_variance   | 0.408        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.327        |\n|    n_updates            | 260          |\n|    policy_gradient_loss | -0.00116     |\n|    value_loss           | 0.843        |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 479          |\n|    ep_rew_mean          | 39.55381     |\n| time/                   |              |\n|    fps                  | 400          |\n|    iterations           | 28           |\n|    time_elapsed         | 699          |\n|    total_timesteps      | 280000       |\n| train/                  |              |\n|    approx_kl            | 0.0040709754 |\n|    clip_fraction        | 0.0169       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0446      |\n|    explained_variance   | 0.375        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.607        |\n|    n_updates            | 270          |\n|    policy_gradient_loss | -0.000551    |\n|    value_loss           | 1.1          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 525          |\n|    ep_rew_mean          | 44.014767    |\n| time/                   |              |\n|    fps                  | 399          |\n|    iterations           | 29           |\n|    time_elapsed         | 725          |\n|    total_timesteps      | 290000       |\n| train/                  |              |\n|    approx_kl            | 0.0014121191 |\n|    clip_fraction        | 0.0184       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0435      |\n|    explained_variance   | 0.433        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.346        |\n|    n_updates            | 280          |\n|    policy_gradient_loss | -4.87e-05    |\n|    value_loss           | 0.83         |\n------------------------------------------\nEval num_timesteps=300000, episode_reward=82.46 +/- 45.92\nEpisode length: 947.20 +/- 486.69\n------------------------------------------\n| eval/                   |              |\n|    mean_ep_length       | 947          |\n|    mean_reward          | 82.5         |\n| time/                   |              |\n|    total_timesteps      | 300000       |\n| train/                  |              |\n|    approx_kl            | 0.0021875892 |\n|    clip_fraction        | 0.0149       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0424      |\n|    explained_variance   | 0.512        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.503        |\n|    n_updates            | 290          |\n|    policy_gradient_loss | -0.00144     |\n|    value_loss           | 0.889        |\n------------------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/           |           |\n|    ep_len_mean     | 539       |\n|    ep_rew_mean     | 45.875744 |\n| time/              |           |\n|    fps             | 394       |\n|    iterations      | 30        |\n|    time_elapsed    | 759       |\n|    total_timesteps | 300000    |\n----------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 553          |\n|    ep_rew_mean          | 47.31873     |\n| time/                   |              |\n|    fps                  | 395          |\n|    iterations           | 31           |\n|    time_elapsed         | 784          |\n|    total_timesteps      | 310000       |\n| train/                  |              |\n|    approx_kl            | 0.0039456817 |\n|    clip_fraction        | 0.0191       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.0446      |\n|    explained_variance   | 0.392        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.802        |\n|    n_updates            | 300          |\n|    policy_gradient_loss | -0.000221    |\n|    value_loss           | 1.2          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 551         |\n|    ep_rew_mean          | 47.017776   |\n| time/                   |             |\n|    fps                  | 395         |\n|    iterations           | 32          |\n|    time_elapsed         | 809         |\n|    total_timesteps      | 320000      |\n| train/                  |             |\n|    approx_kl            | 0.004644259 |\n|    clip_fraction        | 0.0202      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.0461     |\n|    explained_variance   | 0.511       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.524       |\n|    n_updates            | 310         |\n|    policy_gradient_loss | -0.000919   |\n|    value_loss           | 1           |\n-----------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 586           |\n|    ep_rew_mean          | 50.21877      |\n| time/                   |               |\n|    fps                  | 395           |\n|    iterations           | 33            |\n|    time_elapsed         | 834           |\n|    total_timesteps      | 330000        |\n| train/                  |               |\n|    approx_kl            | 0.00089973246 |\n|    clip_fraction        | 0.0102        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.0429       |\n|    explained_variance   | 0.423         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 0.388         |\n|    n_updates            | 320           |\n|    policy_gradient_loss | -0.0011       |\n|    value_loss           | 1.32          |\n-------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 545         |\n|    ep_rew_mean          | 46.29984    |\n| time/                   |             |\n|    fps                  | 395         |\n|    iterations           | 34          |\n|    time_elapsed         | 859         |\n|    total_timesteps      | 340000      |\n| train/                  |             |\n|    approx_kl            | 0.002152094 |\n|    clip_fraction        | 0.0249      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.0418     |\n|    explained_variance   | 0.448       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.74        |\n|    n_updates            | 330         |\n|    policy_gradient_loss | -0.00109    |\n|    value_loss           | 0.998       |\n-----------------------------------------\nEval num_timesteps=350000, episode_reward=109.82 +/- 128.82\nEpisode length: 1279.60 +/- 1535.40\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 1.28e+03    |\n|    mean_reward          | 110         |\n| time/                   |             |\n|    total_timesteps      | 350000      |\n| train/                  |             |\n|    approx_kl            | 0.002016582 |\n|    clip_fraction        | 0.0192      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.0364     |\n|    explained_variance   | 0.406       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.6         |\n|    n_updates            | 340         |\n|    policy_gradient_loss | -2.11e-05   |\n|    value_loss           | 1.35        |\n-----------------------------------------\nNew best mean reward!\nStopping training because the mean reward 109.82  is above the threshold 100.0\n","output_type":"stream"}],"execution_count":5}]}